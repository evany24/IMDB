{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5843137a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59fecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "import glob\n",
    "\n",
    "# Additional Imports\n",
    "import os, json, math, time\n",
    "import tmdbsimple as tmdb\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf7a75",
   "metadata": {},
   "source": [
    "# Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7aac158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d70399d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_with_rating(movie_id):\n",
    "    \"\"\"Copied from Coding Dojo Learning Platform\"\"\"\n",
    "    # Get the movie object for the current id\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "    # save the .info .releases dictionaries\n",
    "    info = movie.info()\n",
    "    releases = movie.releases()\n",
    "    # Loop through countries in releases\n",
    "    for c in releases['countries']:\n",
    "        # if the country abbreviation==US\n",
    "        if c['iso_3166_1' ] =='US':\n",
    "            ## save a \"certification\" key in the info dict with the certification\n",
    "            info['certification'] = c['certification']\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d421d65b",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe6de75",
   "metadata": {},
   "source": [
    "## Title Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af39561f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0035423</td>\n",
       "      <td>movie</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>Kate &amp; Leopold</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>Comedy,Fantasy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0043139</td>\n",
       "      <td>movie</td>\n",
       "      <td>Life of a Beijing Policeman</td>\n",
       "      <td>Wo zhe yi bei zi</td>\n",
       "      <td>0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>Drama,History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0062336</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Tango of the Widower and Its Distorting Mi...</td>\n",
       "      <td>El tango del viudo y su espejo deformante</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0069049</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>The Other Side of the Wind</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0088751</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Naked Monster</td>\n",
       "      <td>The Naked Monster</td>\n",
       "      <td>0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>Comedy,Horror,Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81824</th>\n",
       "      <td>tt9914942</td>\n",
       "      <td>movie</td>\n",
       "      <td>Life Without Sara Amat</td>\n",
       "      <td>La vida sense la Sara Amat</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81825</th>\n",
       "      <td>tt9915872</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Last White Witch</td>\n",
       "      <td>My Girlfriend is a Wizard</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "      <td>Comedy,Drama,Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81826</th>\n",
       "      <td>tt9916170</td>\n",
       "      <td>movie</td>\n",
       "      <td>The Rehearsal</td>\n",
       "      <td>O Ensaio</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81827</th>\n",
       "      <td>tt9916190</td>\n",
       "      <td>movie</td>\n",
       "      <td>Safeguard</td>\n",
       "      <td>Safeguard</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>Action,Adventure,Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81828</th>\n",
       "      <td>tt9916362</td>\n",
       "      <td>movie</td>\n",
       "      <td>Coven</td>\n",
       "      <td>Akelarre</td>\n",
       "      <td>0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92</td>\n",
       "      <td>Drama,History</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81829 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tconst titleType                                       primaryTitle  \\\n",
       "0      tt0035423     movie                                     Kate & Leopold   \n",
       "1      tt0043139     movie                        Life of a Beijing Policeman   \n",
       "2      tt0062336     movie  The Tango of the Widower and Its Distorting Mi...   \n",
       "3      tt0069049     movie                         The Other Side of the Wind   \n",
       "4      tt0088751     movie                                  The Naked Monster   \n",
       "...          ...       ...                                                ...   \n",
       "81824  tt9914942     movie                             Life Without Sara Amat   \n",
       "81825  tt9915872     movie                               The Last White Witch   \n",
       "81826  tt9916170     movie                                      The Rehearsal   \n",
       "81827  tt9916190     movie                                          Safeguard   \n",
       "81828  tt9916362     movie                                              Coven   \n",
       "\n",
       "                                   originalTitle  isAdult  startYear  endYear  \\\n",
       "0                                 Kate & Leopold        0     2001.0      NaN   \n",
       "1                               Wo zhe yi bei zi        0     2013.0      NaN   \n",
       "2      El tango del viudo y su espejo deformante        0     2020.0      NaN   \n",
       "3                     The Other Side of the Wind        0     2018.0      NaN   \n",
       "4                              The Naked Monster        0     2005.0      NaN   \n",
       "...                                          ...      ...        ...      ...   \n",
       "81824                 La vida sense la Sara Amat        0     2019.0      NaN   \n",
       "81825                  My Girlfriend is a Wizard        0     2019.0      NaN   \n",
       "81826                                   O Ensaio        0     2019.0      NaN   \n",
       "81827                                  Safeguard        0     2020.0      NaN   \n",
       "81828                                   Akelarre        0     2020.0      NaN   \n",
       "\n",
       "       runtimeMinutes                     genres  \n",
       "0                 118     Comedy,Fantasy,Romance  \n",
       "1                 120              Drama,History  \n",
       "2                  70                      Drama  \n",
       "3                 122                      Drama  \n",
       "4                 100       Comedy,Horror,Sci-Fi  \n",
       "...               ...                        ...  \n",
       "81824              74                      Drama  \n",
       "81825              97       Comedy,Drama,Fantasy  \n",
       "81826              51                      Drama  \n",
       "81827              95  Action,Adventure,Thriller  \n",
       "81828              92              Drama,History  \n",
       "\n",
       "[81829 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basics = pd.read_csv(r\"C:\\Users\\Evan\\Documents\\Github\\IMDB\\Data\\title_basics.csv.gz\")\n",
    "basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b9813e",
   "metadata": {},
   "source": [
    "# API Extraction from TMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3404ba1",
   "metadata": {},
   "source": [
    "## Create API Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd5c365b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['client-id', 'api-key'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('/Users/Evan/.secret/tmdb_api.json', 'r') as f:\n",
    "    login = json.load(f)\n",
    "## Display the keys of the loaded dict\n",
    "login.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a123c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb.API_KEY =  login['api-key']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c9e1af",
   "metadata": {},
   "source": [
    "## Folders to store and keep existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22d947a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_tmdb_data_2000.csv.gz',\n",
       " 'final_tmdb_data_2001.csv.gz',\n",
       " 'title_akas.csv.gz',\n",
       " 'title_basics.csv.gz',\n",
       " 'title_ratings.csv.gz',\n",
       " 'tmdb_api_results_2000.json',\n",
       " 'tmdb_api_results_2001.json',\n",
       " 'tmdb_results_combined.csv.gz']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLDER = 'Data/'\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dba0af5",
   "metadata": {},
   "source": [
    "## Specify range of years to pull with API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f101804",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS_TO_GET = range(2010, 2023)\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af48b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abc775ae3454062adf7d8c719f8af5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YEARS:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6f17d444d041c194a4e03d6f44facc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2010:   0%|          | 0/3861 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Adapted from Coding Dojo Learning Platform\"\"\"\n",
    "#START OF OUTER LOOP\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):\n",
    "    \n",
    "    #Defining the JSON file to store results for year\n",
    "    JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "\n",
    "    # Check if file exists\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "    # If it does not exist: create it\n",
    "    if file_exists == False:\n",
    "        # save an empty dict with just \"imdb_id\" to the new json file.\n",
    "        with open(JSON_FILE,'w') as f:\n",
    "            json.dump([{'imdb_id':0}],f)\n",
    "\n",
    "    #Saving new year as the current df\n",
    "    #Filter for basics df for only specific year\n",
    "    df = basics[basics['startYear']==YEAR].copy()\n",
    "    # saving movie ids to list\n",
    "    movie_ids = df['tconst'].copy()\n",
    "    \n",
    "    ###Stop gap measure to insure previously retrieved data isn't retrieved again\n",
    "    # Load existing data from json into a dataframe called \"previous_df\"\n",
    "    previous_df = pd.read_json(JSON_FILE)\n",
    "\n",
    "    # filter out any ids that are already in the JSON_FILE\n",
    "    movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "    \n",
    "#INNER LOOP\n",
    "    \n",
    "    #Get index and movie id from list\n",
    "    for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                  desc=f'Movies from {YEAR}',\n",
    "                                  position=1,\n",
    "                                  leave=True):\n",
    "        try:\n",
    "            # Retrieve the data for the movie id\n",
    "            temp = get_movie_with_rating(movie_id)  \n",
    "            # Append/extend results to existing file using a pre-made function\n",
    "            write_json(temp,JSON_FILE)\n",
    "            # Short 20 ms sleep to prevent overwhelming server\n",
    "            time.sleep(0.02)\n",
    "\n",
    "        except Exception as e:\n",
    "            errors.append([movie_id, e])\n",
    "#END OF INNER LOOP\n",
    "    \n",
    "#SECOND PART OF OUTERLOOP\n",
    "    \n",
    "    #save file as .csv.gz  \n",
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", \n",
    "                         compression=\"gzip\", index=False)\n",
    "\n",
    "# print number of errors\n",
    "print(f\"- Total errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0f964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Glob to Combine Files from 2010 to 2023\n",
    "q = \"Data/final_tmdb_data_*.csv.gz\"\n",
    "chunked_files = glob.glob(q)\n",
    "# Showing the first 5\n",
    "files_to_get = chunked_files[2:]\n",
    "files_to_get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading all files as df and appending to a list\n",
    "df_list = []\n",
    "for file in files_to_get:\n",
    "    temp_df = pd.read_csv(file, index_col=0)\n",
    "    df_list.append(temp_df)\n",
    "    \n",
    "## Concatenating the list of dfs into 1 combined\n",
    "df_combined = pd.concat(df_list)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87826d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.drop(index=0, inplace=True)\n",
    "df_combined.drop(index='0', inplace=True)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131dfd5e",
   "metadata": {},
   "source": [
    "### Clean Groups\n",
    "- Will change:\n",
    " - PG-13 with extra white space to PG-13\n",
    " - 10 to G\n",
    " - Unrated to NR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624b50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['certification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8fd744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['certification'] = df_combined['certification'].str.replace('10', 'PG')\n",
    "df_combined['certification'] = df_combined['certification'].str.replace('PG-13 ', 'PG-13')\n",
    "df_combined['certification'] = df_combined['certification'].str.replace('Unrated', 'NR')\n",
    "df_combined['certification'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e1bebc",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed428ee0",
   "metadata": {},
   "source": [
    "## Question 1: Does the MPAA(G/PG/PG-13/R) rating of a movie affect how much revenue the movie generates?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b24baae",
   "metadata": {},
   "source": [
    "### Step 1: State Null/Alternative Hypothesis\n",
    "\n",
    "- **Null Hypothesis:** The movie rating does not affect how much revenue a movie generates\n",
    "\n",
    "\n",
    "- **Alternative Hypothesis:** The movie ratings have a significant affect on how much revenue a movie generates\n",
    "\n",
    "\n",
    "- **Alpha:** .05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080bf924",
   "metadata": {},
   "source": [
    "### STEP 2: Type of Test\n",
    "\n",
    "- **ANOVA**\n",
    " - Comparing numeric data: revenue\n",
    " - More than 2 groups: G, PG, PG-13, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1662e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_combined.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3276df82",
   "metadata": {},
   "source": [
    "#### We should drop the movies with ratings of NR and NC-17 as were are not dealing with these ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f77001",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[(df1['certification'] != 'NR') & (df1['certification'] != 'NC-17')]\n",
    "df1['certification'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693393b3",
   "metadata": {},
   "source": [
    "### Separate into groups based on rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01345c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {}\n",
    "## Loop through all unique categories\n",
    "for i in df1['certification'].unique():\n",
    "    ## Get series for group and rename\n",
    "    data = df1.loc[df1['certification']==i,'revenue'].copy()\n",
    "    \n",
    "    # save into the dictionary\n",
    "    groups[i] = data\n",
    "groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://stackoverflow.com/questions/24068306/\n",
    "# is-there-a-way-to-remove-nan-from-a-dictionary-filled-with-data\n",
    "# Raghul Raj\n",
    "groups = {k: groups[k] for k in groups if not pd.isna(k)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715de5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8921bdd5",
   "metadata": {},
   "source": [
    "### Step 3: Assumptions\n",
    "- No significant outliers\n",
    "- Normality\n",
    "- Equal Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461621d3",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2134f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in groups:\n",
    "    print(f'{i} - Number of rows: {len(groups[i])}')\n",
    "    z_score = stats.zscore(groups[i])\n",
    "    outliers = abs(z_score)>3\n",
    "    print(f'{i} - Number of outliers: {np.sum(outliers)}')\n",
    "    \n",
    "    groups[i] = groups[i][~outliers]\n",
    "    print(f'{i} - Number of rows: {len(groups[i])}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35ac45c",
   "metadata": {},
   "source": [
    "#### Normality\n",
    "- The groups all have > 15 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5737a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running normal test on each group and confirming there are >20 in each group\n",
    "norm_results = {}\n",
    "for i, data in groups.items():\n",
    "    stat, p = stats.normaltest(data)\n",
    "    ## save the p val, test statistic, and the size of the group\n",
    "    norm_results[i] = {'n': len(data),\n",
    "                             'p':p,\n",
    "                             'test stat':stat,}\n",
    "## convert to a dataframe\n",
    "norm_results_df = pd.DataFrame(norm_results).T\n",
    "norm_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3092380",
   "metadata": {},
   "source": [
    "#### Equal Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9753ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.levene(*groups.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40567e",
   "metadata": {},
   "source": [
    "### Step 4: Perform Test and Interpret Result\n",
    "- Since Equal Variance assumption was no met:\n",
    "\n",
    " - We will run Kruskal-Wallis test\n",
    " \n",
    " \n",
    "- p value < 0.05(alpha), reject Null Hypothesis and support Alternative Hypothesis that movie rating does indeed affect revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a2565",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_q1 = stats.kruskal( *groups.values())\n",
    "result_q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62bc0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## is our result significant\n",
    "print(f\"p-value={result_q1.pvalue:.10f}\")\n",
    "print(f\"Significant: {result_q1.pvalue <.05}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b01955",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee0de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df = pd.DataFrame(index=[0], data={'revenue': 0, 'certification':0})\n",
    "groups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df.drop(index=0, inplace=True)\n",
    "groups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax = sns.barplot(data=groups_df, x=groups_df['certification'], y=groups_df['revenue'])\n",
    "ax.set_title('Certification by Revenue');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec47f218",
   "metadata": {},
   "source": [
    "### Step 5: Pairwise Tukey Comparison Test\n",
    "- Shows 4 significant results\n",
    " - reject column\n",
    "- Reject null hypothesis for groups:\n",
    "    - G and PG\n",
    "    - G and PG-13\n",
    "    - PG and R\n",
    "    - PG-13 and R\n",
    "- There is a significant difference in the results of Ratings PG and PG-13 compared to the other 2 ratings\n",
    "- PG and PG-13 show the most revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a5c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = groups_df['revenue']\n",
    "labels = groups_df['certification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb107824",
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey_q1 = pairwise_tukeyhsd(values, labels)\n",
    "tukey_q1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0502b54e",
   "metadata": {},
   "source": [
    "## Question 2: Do movies that are over 2.5 hours long earn more revenue than movies that are 1.5 hours long or less"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3521afab",
   "metadata": {},
   "source": [
    "### STEP 1: State Null/Alternative Hypothesis\n",
    "- Null Hypothesis: there is no difference in earned revenue between movies that are over 2.5 hours long and movies that are 1.5 hours long (or less)\n",
    "\n",
    "- Alternative Hypothesis: there is a difference in earned revenue between movies that are over 2.5 hours long and movies that are 1.5 hours long (or less)\n",
    "\n",
    "- Alpha: 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c8f620",
   "metadata": {},
   "source": [
    "### STEP 2: Type of Test\n",
    "- Independent T-test:\n",
    " - Comparing numeric data: revenue\n",
    " - Comparing 2 samples: movies that are over 2.5 hours long and movies that are 1.5 hours (or less) long\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65b0e4",
   "metadata": {},
   "source": [
    "#### Create 2 Groups of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_movie\n",
    "long_movie = df_combined[df_combined['runtime'] >= 150]\n",
    "long_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de39711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short movie\n",
    "short_movie = df_combined[df_combined['runtime'] <= 90]\n",
    "short_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505996c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_revenue = long_movie['revenue']\n",
    "short_revenue = short_movie['revenue']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b99372",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593847f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long revenue\n",
    "zscores_long = stats.zscore(long_revenue)\n",
    "outliers_long = abs(zscores_long)>3\n",
    "print(f'Len: {len(long_revenue)}')\n",
    "print(f'Number of Ouliers: {np.sum(outliers_long)}')\n",
    "\n",
    "long_revenue = long_revenue[~outliers_long]\n",
    "print(f'Len: {len(long_revenue)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa930f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short revenue\n",
    "zscores_short = stats.zscore(short_revenue)\n",
    "outliers_short = abs(zscores_short)>3\n",
    "print(f'Len: {len(short_revenue)}')\n",
    "print(f'Number of Ouliers: {np.sum(outliers_short)}')\n",
    "\n",
    "short_revenue = short_revenue[~outliers_short]\n",
    "print(f'Len: {len(short_revenue)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ea39f2",
   "metadata": {},
   "source": [
    "#### Normality\n",
    "- Since both groups have sample count > 15, can skip this step entirely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1071b74",
   "metadata": {},
   "source": [
    "#### Equal Variance\n",
    "- Equal Variance assumption is not met\n",
    "- Will add equal_var = False to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c8546",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.levene(long_revenue, short_revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa03114",
   "metadata": {},
   "source": [
    "### STEP 4: Perform Test & Interpret Result\n",
    "- p value < .05, reject null hypothesis and support alternative hypothesis\n",
    "\n",
    "\n",
    "- Runtime length does not affect revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffecea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_q2 = stats.ttest_ind(long_revenue, short_revenue, equal_var=False)\n",
    "result_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e6aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## is our result significant\n",
    "print(f\"p-value={result_q2.pvalue:.10f}\")\n",
    "print(f\"Significant: {result_q2.pvalue <.05}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d5987f",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = pd.DataFrame(long)\n",
    "long_df['runtime'] = 'long'\n",
    "long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe318f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df = pd.DataFrame(short)\n",
    "short_df['runtime'] = 'short'\n",
    "short_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e563adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_q2 = pd.concat([long_df, short_df])\n",
    "plot_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077cd2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Long Movie Revenue: {long.mean():,.2f}')\n",
    "print(f'Short Movie Revenue: {short.mean():,.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7127321",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax = sns.barplot(data=plot_q2, x='runtime', y='revenue')\n",
    "ax.set_title('Runtime by Revenue');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
